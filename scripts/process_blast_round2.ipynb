{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a5cbea6-b949-4b9a-868e-4f650d4c0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load filtered round2 blast chimeras\n",
    "import pickle\n",
    "file_path = 'outputs/round2_chimera_intervals.pickle'\n",
    "with open(file_path, 'rb') as file:\n",
    "    chimeras=pickle.load(file)\n",
    "##append to intervals\n",
    "intervals=[]\n",
    "for c in chimeras:\n",
    "    for i in chimeras[c]:\n",
    "        intervals.append(c+\";\"+chimeras[c][i]+\"_\"+str(i).replace(\" \",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e479a92-d4d0-4ec3-ab0f-81a46ddf8fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##add headers to round2 diamond outputs\n",
    "for n in os.listdir('outputs/round2_diamond_output_split'):\n",
    "    df=pd.read_csv(f\"outputs/round2_diamond_output_split/{n}.tsv\",sep=\"\\t\", names=\"qseqid sseqid stitle staxids sscinames sphylums skingdoms pident length mismatch gapopen qstart qend sstart send evalue bitscore\".split(\" \"))\n",
    "    df.to_csv(f\"outputs/round2_diamond_output_split/{n}.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55a0b17a-3429-4506-a2cb-2e3494301ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import subprocess\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def check_annot(n):\n",
    "    \"\"\"\n",
    "    takes the name of an interval blast dataframe (string) stored in round2_diamond_output_split\n",
    "    returns \"Meta\", \"HGT\" or none annotations\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df=pd.read_csv(f\"outputs/round2_diamond_output_split/{n}.tsv\",sep=\"\\t\")\n",
    "    \n",
    "    leng=len(record_dict[n.split('.tsv')[0]].seq)\n",
    "    df[\"cov\"]=(np.array(df.qend)-np.array(df.qstart)+1)/leng\n",
    "    #filter by >30% coverage of the query\n",
    "    dfo=df[df[\"cov\"]>.30]\n",
    "    dfo=dfo[~dfo.sphylums.astype(str).str.contains(\"Arthropoda\")]\n",
    "    dfo=dfo[~dfo.sphylums.astype(str).str.contains(\"Rotifera\")]\n",
    "    dfo=dfo[dfo.staxids.astype(str)!=\"nan\"]\n",
    "    ##exclude synthetic sequences\n",
    "    dfm=dfo[dfo.staxids!=32630]\n",
    "    \n",
    "    dfmeta=dfm[dfm.skingdoms.astype(str).str.contains(\"Metazoa\")]\n",
    "    dfhgt=dfm[~dfm.skingdoms.astype(str).str.contains(\"Metazoa\")]\n",
    "    dfhgt[\"AI\"]=np.log10(dfmeta.evalue.min()+1e-200)-np.log10(dfhgt.evalue+1e-200)\n",
    "    dfmeta[\"MI\"]=np.log10(dfhgt.evalue.min()+1e-200)-np.log10(dfmeta.evalue+1e-200)\n",
    "    \n",
    "    ##get the top 300 hits by lowest evalue\n",
    "    dfmi=dfm.iloc[0:300,:]\n",
    "    dfmetai=dfmi[dfmi.skingdoms.astype(str).str.contains(\"Metazoa\")]\n",
    "    dfhgti=dfmi[~dfmi.skingdoms.astype(str).str.contains(\"Metazoa\")]\n",
    "\n",
    "\n",
    "    hgt_condition= (dfhgt.evalue.min()<1e-4 or dfhgt.bitscore.max()>50) and len(set(dfhgt.staxids))>10 and (len(set(dfhgt[dfhgt.AI>5].staxids))>10 or len(set(dfhgti.staxids))/len(set(dfmi.staxids))>=.95)\n",
    "    meta_condition= dfmeta.evalue.min()<.1  and (len(set(dfmeta[dfmeta.MI>1].staxids))>5 or (len(set(dfmetai.staxids))/len(set(dfmi.staxids))>=.50))\n",
    "    if dfm.shape[0]>0:\n",
    "        # print(dfhgt.evalue.min(), dfmetai.shape[0])\n",
    "        if meta_condition:\n",
    "            return \"Meta\"\n",
    "        elif hgt_condition:\n",
    "            return \"HGT\"\n",
    "    return\n",
    "\n",
    "record_dict=SeqIO.to_dict(SeqIO.parse('outputs/split_intervals.fasta', 'fasta'))\n",
    "meta=[x.split(\".tsv\")[0] for x in os.listdir(\"outputs/round2_diamond_output_split\") if \"Meta\" in x]\n",
    "hgt=[x.split(\".tsv\")[0] for x in os.listdir(\"outputs/round2_diamond_output_split\") if \"HGT\" in x]\n",
    "\n",
    "#annotate putative HGT intervals and store confirmed ones\n",
    "with mp.Pool(28) as p:\n",
    "    hgts2 = p.map(check_annot, hgt)\n",
    "#dictionary between hgt interval and updated annotation\n",
    "hgt_map={x:y for x,y in zip(hgt,hgts2)}\n",
    "hgt_set=set([x.split(\";\")[0]+\";\"+x.split(\";\")[1] for x in hgt_map if hgt_map[x]==\"HGT\"])\n",
    "\n",
    "#annotate putative metazoan intervals and store confirmed ones\n",
    "with mp.Pool(28) as p:\n",
    "    meta2 = p.map(check_annot, meta)\n",
    "#dictionary between meta interval and updated annotation\n",
    "meta_map={x:y for x,y in zip(meta,meta2)}\n",
    "meta_set=set([x.split(\";\")[0]+\";\"+x.split(\";\")[1] for x in meta_map if meta_map[x]==\"Meta\"])\n",
    "\n",
    "#select chimeras: contain confirmed HGT and Meta intervals\n",
    "chimeras_filtered=meta_set&hgt_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e890596-92d3-4cbf-8e54-b55cf23e275d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chimeras_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "578b88b4-a5e4-4d5b-8103-74c7af64d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hgt_data(n):\n",
    "    \"\"\"\n",
    "    takes the name of an HGT interval blast dataframe (string) stored in round2_diamond_output_split\n",
    "    returns summary statistics used for hgt inference\n",
    "    \"\"\"\n",
    "    df=pd.read_csv(f\"outputs/round2_diamond_output_split/{n}.tsv\",sep=\"\\t\")\n",
    "    leng=len(record_dict[n.split('.tsv')[0]].seq)\n",
    "    df[\"cov\"]=(np.array(df.qend)-np.array(df.qstart)+1)/leng\n",
    "    #filter by >30% coverage of the query\n",
    "    dfo=df[df[\"cov\"]>.30]\n",
    "    dfo=dfo[~dfo.sphylums.astype(str).str.contains(\"Arthropoda\")]\n",
    "    dfo=dfo[~dfo.sphylums.astype(str).str.contains(\"Rotifera\")]\n",
    "    dfo=dfo[dfo.staxids.astype(str)!=\"nan\"]\n",
    "    ##exclude synthetic sequences\n",
    "    dfm=dfo[dfo.staxids!=32630]\n",
    "\n",
    "    dfmeta=dfm[dfm.skingdoms.astype(str).str.contains(\"Metazoa\")]\n",
    "    dfhgt=dfm[~dfm.skingdoms.astype(str).str.contains(\"Metazoa\")]\n",
    "    dfhgt[\"AI\"]=np.log10(dfmeta.evalue.min()+1e-200)-np.log10(dfhgt.evalue+1e-200)\n",
    "    dfmeta[\"MI\"]=np.log10(dfhgt.evalue.min()+1e-200)-np.log10(dfmeta.evalue+1e-200)\n",
    "\n",
    "    ##get the top 300 hits by lowest evalue\n",
    "    dfmi=dfm.iloc[0:300,:]\n",
    "    dfmetai=dfmi[dfmi.skingdoms.astype(str).str.contains(\"Metazoa\")]\n",
    "    dfhgti=dfmi[~dfmi.skingdoms.astype(str).str.contains(\"Metazoa\")]\n",
    "\n",
    "    return list(dfhgt.loc[dfhgt.bitscore.idxmax(),['bitscore']])+list(dfhgt.loc[dfhgt.evalue.idxmin(),['evalue', 'cov','stitle','sscinames','sphylums','skingdoms']])+[dfmeta.shape[0], len(set(dfhgt.staxids)),len(set(dfhgti.staxids))/len(set(dfmi.staxids)),dfhgt.AI.max(),len(set(dfhgt[dfhgt.AI>5].staxids))]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41753de1-374f-4f11-b093-c8d24e10afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_data(n):\n",
    "    \"\"\"\n",
    "    takes the name of a netazoan interval blast dataframe (string) stored in round2_diamond_output_split\n",
    "    returns summary statistics used for hgt inference\n",
    "    \"\"\"\n",
    "    df=pd.read_csv(f\"outputs/round2_diamond_output_split/{n}.tsv\",sep=\"\\t\")\n",
    "    leng=len(record_dict[n.split('.tsv')[0]].seq)\n",
    "    df[\"cov\"]=(np.array(df.qend)-np.array(df.qstart)+1)/leng\n",
    "    #filter by >30% coverage of the query\n",
    "    dfo=df[df[\"cov\"]>.30]\n",
    "    dfo=dfo[~dfo.sphylums.astype(str).str.contains(\"Arthropoda\")]\n",
    "    dfo=dfo[~dfo.sphylums.astype(str).str.contains(\"Rotifera\")]\n",
    "    dfo=dfo[dfo.staxids.astype(str)!=\"nan\"]\n",
    "    ##exclude synthetic sequences\n",
    "    dfm=dfo[dfo.staxids!=32630]\n",
    "\n",
    "    dfmeta=dfm[dfm.skingdoms.astype(str).str.contains(\"Metazoa\")]\n",
    "    dfhgt=dfm[~dfm.skingdoms.astype(str).str.contains(\"Metazoa\")]\n",
    "    dfhgt[\"AI\"]=np.log10(dfmeta.evalue.min()+1e-200)-np.log10(dfhgt.evalue+1e-200)\n",
    "    dfmeta[\"MI\"]=np.log10(dfhgt.evalue.min()+1e-200)-np.log10(dfmeta.evalue+1e-200)\n",
    "\n",
    "    ##get the top 300 hits by lowest evalue\n",
    "    dfmi=dfm.iloc[0:300,:]\n",
    "    dfmetai=dfmi[dfmi.skingdoms.astype(str).str.contains(\"Metazoa\")]\n",
    "    dfhgti=dfmi[~dfmi.skingdoms.astype(str).str.contains(\"Metazoa\")]\n",
    "\n",
    "    return list(dfmeta.loc[dfmeta.bitscore.idxmax(),['bitscore']])+list(dfmeta.loc[dfmeta.evalue.idxmin(),['evalue','cov','stitle','sscinames','sphylums','skingdoms']])+[dfmeta.shape[0], len(set(dfmeta.staxids)),len(set(dfmetai.staxids))/len(set(dfmi.staxids)),dfmeta.MI.max(),len(set(dfmeta[dfmeta.MI>1].staxids))]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b7e5f6a-07f9-40b2-9808-a57ea0622917",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Output a dataframe with summary statistics for hgt intervals\n",
    "hgt_confirmed=[x for x in hgt_map if \";\".join(x.split(';')[0:2]) in chimeras_filtered and hgt_map[x]=='HGT']\n",
    "with mp.Pool(28) as p:\n",
    "    hgt_data = p.map(get_hgt_data, hgt_confirmed)\n",
    "hgt_df=pd.DataFrame(index=hgt_confirmed)\n",
    "hgt_df.loc[:, ['bitscore_max','min_evalue','evalue_min_cov','evalue_min_title','evalue_min_sciname','evalue_min_phylum','evalue_min_kingdom','n_meta_hits','n_hgt_taxids','p_HGT300','AI','N_AI>5']]=hgt_data\n",
    "hgt_df.to_csv(\"outputs/round2_blast_statistics_hgt_intervals.tsv\",sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "211ad16b-1132-47fe-ac34-ec214452e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Output a dataframe with summary statistics for meta intervals\n",
    "meta_confirmed=[x for x in meta_map if \";\".join(x.split(';')[0:2]) in chimeras_filtered and meta_map[x]=='Meta']\n",
    "with mp.Pool(28) as p:\n",
    "    meta_data = p.map(get_meta_data, meta_confirmed)\n",
    "meta_df=pd.DataFrame(index=meta_confirmed)\n",
    "meta_df.loc[:, ['bitscore_max','evalue_min','evalue_min_cov','evalue_min_title','evalue_min_sciname','evalue_min_phylum','evalue_min_kingdom','n_meta_hits','n_hgt_taxids','p_Meta300','MI','N_MI>1']]=meta_data\n",
    "meta_df.to_csv(\"outputs/round2_blast_statistics_meta_intervals.tsv\",sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92a6993c-3b5d-443f-aa52-8244c9810eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "##make a dict of dicts chimera_name:interval tuple:HGT/Meta annot \n",
    "chimeras_filtered_dict=defaultdict(dict)\n",
    "for x in chimeras_filtered:\n",
    "    m={ast.literal_eval(xm.split(\"_\")[-1]):xm.split(\";\")[-1].split(\"_\")[0] for xm in meta_confirmed if x in xm}\n",
    "    h={ast.literal_eval(xm.split(\"_\")[-1]):xm.split(\";\")[-1].split(\"_\")[0] for xm in hgt_confirmed if x in xm}\n",
    "    combo=m|h\n",
    "    ##sort dict by intervals\n",
    "    combo = {k: v for k, v in sorted(combo.items(), key=lambda kv: kv[0][0])}\n",
    "    chimeras_filtered_dict[x]=combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a28e0a6-08ec-4077-bdb5-bdea712272a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "parameter: name of an hgt chimera\n",
    "assumes chimeras_filtered_dict is sorted \n",
    "returns whether any adjacent series of HGT, Meta intervals is found in a non-arthropod sequence (boolean)\n",
    "\n",
    "\"\"\"\n",
    "def check_non_arthropod_chimera(n,ethresh=1e-2):\n",
    "    d=chimeras_filtered_dict[n]\n",
    "    intervals=list(d.keys())\n",
    "    for i in range(len(d)):\n",
    "        if d[intervals[i]]=='HGT':\n",
    "            ints=str(intervals[i]).replace(\" \",\"\")\n",
    "            df=pd.read_csv(f\"outputs/round2_diamond_output_split/{n};HGT_{ints}.tsv\",sep=\"\\t\", names=\"qseqid sseqid stitle staxids sscinames sphylums skingdoms pident length mismatch gapopen qstart qend sstart send evalue bitscore\".split(\" \"))\n",
    "            df=df[df.evalue<ethresh]\n",
    "            hgts=set(df[~df.sphylums.astype(str).str.contains('Arthropoda')]['sseqid'])\n",
    "            metas=set()\n",
    "            ##check \n",
    "            if i>0 and d[intervals[i-1]]=='Meta' :\n",
    "                ints=str(intervals[i-1]).replace(\" \",\"\")\n",
    "                df=pd.read_csv(f\"outputs/round2_diamond_output_split/{n};Meta_{ints}.tsv\",sep=\"\\t\", names=\"qseqid sseqid stitle staxids sscinames sphylums skingdoms pident length mismatch gapopen qstart qend sstart send evalue bitscore\".split(\" \"))\n",
    "                df=df[df.evalue<ethresh]\n",
    "                metas=metas|set(df[~df.sphylums.astype(str).str.contains('Arthropoda')]['sseqid'])\n",
    "            if i<len(d)-1 and d[intervals[i+1]]=='Meta':\n",
    "                ints=str(intervals[i+1]).replace(\" \",\"\")\n",
    "                df=pd.read_csv(f\"outputs/round2_diamond_output_split/{n};Meta_{ints}.tsv\",sep=\"\\t\", names=\"qseqid sseqid stitle staxids sscinames sphylums skingdoms pident length mismatch gapopen qstart qend sstart send evalue bitscore\".split(\" \"))\n",
    "                df=df[df.evalue<ethresh]\n",
    "                metas=metas|set(df[~df.sphylums.astype(str).str.contains('Arthropoda')]['sseqid'])\n",
    "    return len(metas&hgts)>0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20aa50e6-8afe-432b-9850-bd6b10ff6084",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with mp.Pool(28) as p:\n",
    "    overlap = p.map(check_non_arthropod_chimera, chimeras_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89cbdc02-18a7-4e73-9065-ac42f084c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_dict={x:y for x,y in zip(chimeras_filtered,overlap)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebd0559d-842e-4b82-b120-9d4fd45359e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_overlaps=set([x for x in overlap_dict if not overlap_dict[x]])\n",
    "chimeras_filtered_overlaps={x:chimeras_filtered_dict[x] for x in no_overlaps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0ca8e20-f808-47bc-9b24-02dfa31a9bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##print number of chimeras after filtering out chimeras in which adjacent series of hgt/non-hgt intervals are found in non-arthropod sequences\n",
    "chimeras_filtered_overlaps={x:chimeras_filtered_overlaps[x] for x in chimeras_filtered_overlaps if 'partial' not in record_dict[x].description}\n",
    "len(chimeras_filtered_overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4b53a5a-36e7-4fee-b421-4b6a5c157c6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##output a dictionary of chimera intervals\n",
    "file_path = 'outputs/round2_chimera_intervals.pickle'\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(chimeras_filtered_overlaps,file)\n",
    "\n",
    "##output .txt representation of dictionary of chimera intervals\n",
    "f=open('outputs/round2_chimera_intervals.txt','w')\n",
    "for k,v in chimeras_filtered_overlaps.items():\n",
    "    f.write(f'{k}:{v}\\n')\n",
    "f.close()\n",
    "\n",
    "##output a dictionary of ufll protein lengths, useful for plotting\n",
    "lmap={x:len(record_dict[x].seq) for x in record_dict}\n",
    "with open('outputs/length_map.pickle', 'wb') as file:\n",
    "    pickle.dump(lmap,file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae70775-0008-4521-910a-f726fe2cb2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-rishabh]",
   "language": "python",
   "name": "conda-env-.conda-rishabh-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
