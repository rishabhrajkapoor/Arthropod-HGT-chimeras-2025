{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df19cf33-a28e-442d-a641-4d4b52b5674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9368ef5c-896c-4470-bfdd-8991fbe7b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load chimera mapping to intervals\n",
    "file_path = 'outputs/round2_chimera_intervals.pickle'\n",
    "with open(file_path, 'rb') as file:\n",
    "    chimeras=pickle.load(file)\n",
    "##print the number of hgt-chimeras with repbase annotations\n",
    "len(set([\";\".join(x.split(\";\")[0:2]) for x in repdf.Query_Name])&set((chimeras_filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b11df25a-99b6-492f-9074-c21c573af6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load a dataframe of genome taxids from genome accessions\n",
    "df1=pd.read_csv('Data/genbank_genomes_4_22_2025.tsv',sep='\\t')\n",
    "df2=pd.read_csv('Data/refseq_genomes_scaffold_plus_4_19_2025.tsv',sep='\\t')\n",
    "dftax=pd.concat([df1,df2]).set_index('Assembly Accession')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce98b567-20a1-4df0-82d8-53508b3be0b8",
   "metadata": {},
   "source": [
    "## Filter out ankyrin repeat proteins using  NCBI CD-search hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15bdf9dd-3d36-4486-8945-12614100c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write round 2 chimeras to a fasta for submission to NCBI CD-search webportal https://www.ncbi.nlm.nih.gov/Structure/bwrpsb/bwrpsb.cgi\n",
    "f=open('outputs/round2_chimeras_full_length.fa','w')\n",
    "for x in chimeras:\n",
    "    n=x.split(\";\")[1]\n",
    "    f.write(f\">{n}\\n\")\n",
    "    f.write(str(record_dict[x].seq)+'\\n')\n",
    "f.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "404bf781-597f-46ae-adf6-a12da1900500",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load cd-search results (downloaded from webserver)\n",
    "cdhit=pd.read_csv(\"outputs/round2_chimeras_cdd_search.txt\",sep=\"\\t\")\n",
    "cdhit['Query']=[x.split(\">\")[1] for x in cdhit['Query']]\n",
    "ank=cdhit[cdhit['Short name'].isin(['ANKYR','Ank_2','PHA03095 superfamily','PHA03100 superfamily','ANKYR superfamily','Ank_4','Ank_5','PRANC superfamily'])]\n",
    "no_ank=cdhit[~cdhit['Short name'].isin(['ANKYR','Ank_2','PHA03095 superfamily','PHA03100 superfamily','ANKYR superfamily','Ank_4','Ank_5','PRANC superfamily'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cb852d1-ddf0-48ce-b798-33aacced1568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(set(ank['Query'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f79b386-3a6a-4baf-8768-015741e19703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##filter out ankyrin repeart proteins\n",
    "chimeras_filtered={x:chimeras[x] for x in chimeras if x.split(\";\")[1] not in set(ank.Query)}\n",
    "len(chimeras_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4eb87d2-e4c1-4dd9-83dc-f78b998d4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the number of intervals overlapping ankyrin repeat domains (not reported in manuscript; just for curiosity)\n",
    "def intervals_overlap(interval1, interval2):\n",
    "    start1, end1 = interval1\n",
    "    start2, end2 = interval2\n",
    "\n",
    "    # The intervals overlap if the later start is ≤ the earlier end\n",
    "    return max(start1, start2) <= min(end1, end2)\n",
    "overlaps=[]\n",
    "for chimera in chimeras:\n",
    "    anki=ank[ank.Query==chimera.split(\";\")[1]]\n",
    "    c={}\n",
    "    \n",
    "    for interval in chimeras[chimera]:\n",
    "        add=True\n",
    "        for index, row in anki.iterrows():\n",
    "            if  intervals_overlap(interval,(row['From'],row['To'])):\n",
    "                overlaps.append(chimera+\";\"+chimeras[chimera][interval]+\"_\"+str(interval).replace(\" \",\"\"))\n",
    "                break\n",
    " \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a1471a4-3242-4362-8ac9-805f7c638911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcb1f21d-bfa6-47e8-b4fb-db4b2c5b3f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 60)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in overlaps if 'HGT' in x]),len([x for x in overlaps if 'Meta' in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a621f7-d400-48f5-97b5-bbf3fe39bd96",
   "metadata": {},
   "source": [
    "# Transposable element filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805898ae-68c7-4d79-a8f2-d85b810453a3",
   "metadata": {},
   "source": [
    "Split fastas into chunks for submission to CENSOR on the repbase website https://www.girinst.org/censor/index.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ed0da20-093f-4c51-81ae-616cce72d90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(seq, n=100):\n",
    "    \"\"\"Yield successive n-sized chunks from seq.\"\"\"\n",
    "    for i in range(0, len(seq), n):\n",
    "        yield seq[i:i + n]\n",
    "\n",
    "parts=list(chunks(list(chimeras_filtered), 100))\n",
    "\n",
    "!mkdir split_for_repbase\n",
    "for i in range(len(parts)):\n",
    "    f=open(f'split_for_repbase/{i}.fasta','w')\n",
    "    for p in parts[i]:\n",
    "        f.write(f\">{p}\\n\")\n",
    "        f.write(str(record_dict[p].seq)+'\\n')\n",
    "    f.close()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cc50cd-f663-4bc8-accd-75edc6968916",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parse censor html outputs as a pandas dataframe and fasta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdfe1979-59b5-4306-8217-be1a7f8597b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import sys, re, pathlib\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extract_local_alignments(html_text: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse a CENSOR results page and return a tidy DataFrame containing\n",
    "\n",
    "      • Local Alignments* data (query/hit coords, Dir, Sim, PosMmTs, Score)\n",
    "      • TE_description  – concatenated DE lines for each Hit_Name\n",
    "      • TE_species      – concatenated OS lines for each Hit_Name\n",
    "      • TE_lineage      – concatenated OC lines for each Hit_Name\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    html_text : str\n",
    "        The full HTML of a CENSOR results page.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        One row per alignment with the extra TE_* columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # ── 1. Grab the Local Alignments* section ──────────────────────────────\n",
    "    h2 = re.search(r\"<h2[^>]*>\\s*Local\\s+Alignments\\*\\s*</h2>\", html_text,\n",
    "                   flags=re.I)\n",
    "    if not h2:\n",
    "        raise ValueError(\"Local Alignments* section not found\")\n",
    "    section = html_text[h2.start():]\n",
    "\n",
    "    # Read every <table> in that section (wrap string in StringIO)\n",
    "    tables = pd.read_html(StringIO(section))\n",
    "    align_dfs = [t for t in tables if {'Dir', 'Sim', 'Score'}.issubset(t.columns)]\n",
    "    if not align_dfs:\n",
    "        raise ValueError(\"No Local Alignments tables detected\")\n",
    "    df = pd.concat(align_dfs, ignore_index=True)\n",
    "\n",
    "    # ── 2. Normalise duplicate “Name / From / To” columns ───────────────────\n",
    "    rename, n_name = {}, 0\n",
    "    n_from = n_to = 0\n",
    "    for col in df.columns:\n",
    "        low = col.lower()\n",
    "        if low.startswith(\"name\"):\n",
    "            rename[col] = \"Query_Name\" if n_name == 0 else \"Hit_Name\"; n_name += 1\n",
    "        elif low.startswith(\"from\"):\n",
    "            rename[col] = \"Query_From\" if n_from == 0 else \"Hit_From\"; n_from += 1\n",
    "        elif low.startswith(\"to\"):\n",
    "            rename[col] = \"Query_To\" if n_to == 0 else \"Hit_To\"; n_to += 1\n",
    "        elif \"pos\" in low:\n",
    "            rename[col] = \"PosMmTs\"\n",
    "        else:\n",
    "            rename[col] = col\n",
    "    df = df.rename(columns=rename)\n",
    "\n",
    "    # ── 3. Parse Annotation of Repbase Sequences (<pre> block) ──────────────\n",
    "    pre = re.search(r'Annotation of Repbase Sequences.*?<pre>(.*?)</pre>',\n",
    "                    html_text, flags=re.S)\n",
    "    desc_map, species_map, lineage_map = {}, {}, {}\n",
    "    if pre:\n",
    "        for rec in re.split(r'\\n//\\s*\\n', pre.group(1)):          # split at terminator\n",
    "            m_id = re.search(r'^ID\\s+([^\\s]+)', rec, flags=re.M)\n",
    "            if not m_id:\n",
    "                continue\n",
    "            rid = m_id.group(1)\n",
    "\n",
    "            desc_map[rid]    = \" \".join(re.findall(r'^DE\\s+(.+)$', rec, flags=re.M))\n",
    "            species_map[rid] = \" \".join(re.findall(r'^OS\\s+(.+)$', rec, flags=re.M))\n",
    "            lineage_map[rid] = \" \".join(re.findall(r'^OC\\s+(.+)$', rec, flags=re.M))\n",
    "\n",
    "    # ── 4. Attach TE_* columns ──────────────────────────────────────────────\n",
    "    df[\"TE_description\"] = df[\"Hit_Name\"].map(desc_map).fillna(\"\")\n",
    "    df[\"TE_species\"]     = df[\"Hit_Name\"].map(species_map).fillna(\"\")\n",
    "    df[\"TE_lineage\"]     = df[\"Hit_Name\"].map(lineage_map).fillna(\"\")\n",
    "\n",
    "    # Optional: put columns in a nice order\n",
    "    preferred = [\"Query_Name\", \"Query_From\", \"Query_To\",\n",
    "                 \"Hit_Name\",  \"Hit_From\",  \"Hit_To\",\n",
    "                 \"Dir\", \"Sim\", \"PosMmTs\", \"Score\",\n",
    "                 \"TE_description\", \"TE_species\", \"TE_lineage\"]\n",
    "    df = df[[c for c in preferred if c in df.columns]]\n",
    "\n",
    "    return df\n",
    "import pathlib\n",
    "repdf=pd.DataFrame()\n",
    "for x in range(5):\n",
    "    html_text = pathlib.Path(f'split_for_repbase/{x}_result.html').read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    repdf=pd.concat([repdf,extract_local_alignments(html_text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd749e02-a863-46c7-971c-9b79b22cf40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##print the number of hgt-chimeras with repbase annotations\n",
    "len(set([\";\".join(x.split(\";\")[0:2]) for x in repdf.Query_Name])&set((chimeras_filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64f4b6d2-1804-4c7e-afb9-80d079f9553f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.473568281938326"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##print fraction of hgt-chimeras with repbase annotations \n",
    "len(set([\";\".join(x.split(\";\")[0:2]) for x in repdf.Query_Name])&set((chimeras_filtered)))/len(set((chimeras_filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "254c3085-8797-4536-88f4-680880ef02e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "repdf.to_csv('outputs/censor_repbase_hits.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30494717-d37d-4947-95ab-ba6beec8f588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "621232"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "Extract every CDS translation from the “Annotation of Repbase Sequences”\n",
    "section in a batch of CENSOR HTML reports and write them all to one\n",
    "FASTA file.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import re, textwrap, pathlib, sys\n",
    "\n",
    "# ── regexes ────────────────────────────────────────────────────────────────\n",
    "ANN_RE   = re.compile(r'Annotation of Repbase Sequences.*?<pre>(.*?)</pre>',\n",
    "                      re.S)\n",
    "REC_SPLT = re.compile(r'\\n//\\s*\\n')\n",
    "ID_RE    = re.compile(r'^ID\\s+(\\S+)', re.M)\n",
    "TR_RE    = re.compile(r'/translation=\"([^\"]+)\"', re.S)\n",
    "\n",
    "\n",
    "def extract_cds_from_html(html_path: pathlib.Path) -> list[tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Return a list of (header, aa_sequence) tuples for one CENSOR HTML file.\n",
    "    Header format:  <Repbase-ID>_CDS<n>\n",
    "    \"\"\"\n",
    "    html = html_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    m = ANN_RE.search(html)\n",
    "    if not m:\n",
    "        return []                         # no annotation section in this file\n",
    "\n",
    "    translations: list[tuple[str, str]] = []\n",
    "    for rec in REC_SPLT.split(m.group(1)):\n",
    "        id_m = ID_RE.search(rec)\n",
    "        if not id_m:\n",
    "            continue\n",
    "        rep_id = id_m.group(1)\n",
    "\n",
    "        for idx, match in enumerate(TR_RE.findall(rec), start=1):\n",
    "            aa = re.sub(r\"\\s+\", \"\", match)              # strip whitespace/newlines\n",
    "            translations.append((f\"{rep_id}_CDS{idx}\", aa))\n",
    "\n",
    "    return translations\n",
    "\n",
    "out_path = pathlib.Path(\"outputs/repbase_cds_translations.fasta\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fasta_lines: list[str] = []\n",
    "n_seqs = 0\n",
    "\n",
    "for x in range(5):                                     # adjust range if needed\n",
    "    html_file = pathlib.Path(f\"split_for_repbase/{x}_result.html\")\n",
    "    if not html_file.exists():\n",
    "        print(f\"[warn] {html_file} not found – skipping\", file=sys.stderr)\n",
    "        continue\n",
    "\n",
    "    for header, seq in extract_cds_from_html(html_file):\n",
    "        fasta_lines.append(f\">{header}\")\n",
    "        fasta_lines.extend(textwrap.wrap(seq, 60))\n",
    "        n_seqs += 1\n",
    "\n",
    "if not fasta_lines:\n",
    "    sys.exit(\"No CDS translations found in any input file\")\n",
    "\n",
    "out_path.write_text(\"\\n\".join(fasta_lines))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a1b6006-24a6-4eb8-9350-a816935c303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a dictionary of between HGT intervals that overlap with Metazoan transposons:list of their hits\n",
    "from collections import defaultdict\n",
    "overlapping_metazoan_TEs=defaultdict(list)\n",
    "for c in chimeras_filtered:\n",
    "    rep=repdf[(repdf.Query_Name==c)&(repdf.TE_lineage.str.contains('Metazoa'))]\n",
    "    if rep.shape[0]>=1:\n",
    "        for inter in chimeras_filtered[c]:\n",
    "            if chimeras_filtered[c][inter]=='HGT':\n",
    "                for index, row in rep.iterrows():\n",
    "                    if intervals_overlap((row.Query_From,row.Query_To),inter):\n",
    "                        overlapping_metazoan_TEs[c+';'+'HGT_'+str(inter).replace(' ','')].append(row.Hit_Name)\n",
    "                       \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76bb6a5c-ca71-44c3-b649-38fc5ed1e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "##run diamond blastp of intervals vs concatenated censor protein outputs\n",
    "singularity exec /cvmfs/singularity.galaxyproject.org/d/i/diamond:2.0.15--hb97b32f_1 diamond makedb --in outputs/repbase_cds_translations.fasta --db repbase_cds_translations\n",
    "singularity exec /cvmfs/singularity.galaxyproject.org/d/i/diamond:2.0.15--hb97b32f_1 diamond blastp --db repbase_cds_translations.dmnd --query outputs/split_intervals.fasta --out outputs/diamond_v_repbase.tsv --outfmt 6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore --very-sensitive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86415768-a1d5-4c8b-a925-75d7849709dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rephits=pd.read_csv(\"outputs/diamond_v_repbase.tsv\",sep=\"\\t\",names=\"qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore\".split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6f2dc06-edb6-4bc8-977f-b9e61be5662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## exclude the second cds of medea from metazoan TEs, shown to be bacterial origin https://doi.org/10.1073/pnas.0800444105\n",
    "rephits=rephits[rephits.sseqid!='Medea_CDS2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76581125-a47f-412b-b9b6-b84b9a5fa17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rephits.sseqid=[x.split(\"_CDS\")[0] for x in rephits.sseqid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d338326-68fc-4f7e-a6c9-f56e76dab9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##filter out blast hits with queries with overlapping metazoan TES\n",
    "rephitsfiltered=pd.DataFrame()\n",
    "for x in overlapping_metazoan_TEs:\n",
    "    rephitsfiltered=pd.concat([rephitsfiltered,rephits[(rephits.qseqid==x)]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4e4afe9-9d30-4786-9f98-75d82eab3437",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load top non-metazoan blast hits for comparison to bitscore of TEs\n",
    "for index,row in rephitsfiltered.iterrows():\n",
    "    x=row['qseqid']\n",
    "    dfblast=pd.read_csv(f'outputs/round2_diamond_output_split/{x}.tsv',sep='\\t')\n",
    "    dfblast=dfblast[~(dfblast.skingdoms.astype(str).str.contains('Metazoa'))&~(dfblast.staxids.astype(str).str.contains('32630'))].sort_values('bitscore',ascending=False)\n",
    "    rephitsfiltered.loc[index,['non_meta_top_stitle','non_meta_top_skingdoms','non_meta_top_pident','non_meta_top_bitscore']]=list(dfblast.iloc[0,:].loc[['stitle','skingdoms','pident','bitscore']].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf885755-7357-440a-acae-f9f536c6261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##get top TE hit per query\n",
    "idx = rephitsfiltered.groupby('qseqid')['bitscore'].idxmax()\n",
    "top_hits = rephitsfiltered.loc[idx]          \n",
    "top_hits = top_hits.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "965c6f08-4d86-4662-93cb-f7f4c6fd1538",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bit score ratio of non-metazoan hit to TE hit\n",
    "top_hits['bit_ratio']=top_hits.non_meta_top_bitscore/top_hits.bitscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76103c05-e940-47e7-8beb-2a5a89fb3842",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a tsv of BLAST data for hgt interivals overlapping TEs\n",
    "exclude_TE=top_hits\n",
    "nmap={x:y for x,y in zip(repdf.Hit_Name,repdf.TE_description)}\n",
    "exclude_TE['TE_description'] = [\n",
    "    nmap[x] if x in nmap else 'missing'\n",
    "    for x in exclude_TE.sseqid\n",
    "]\n",
    "exclude_TE['species']=[dftax.loc[x.split(';')[0],'Organism Name'] for x in exclude_TE.qseqid]\n",
    "exclude_TE.columns=['query interval', 'query species', 'TE_ID', 'TE_description', 'TE_pident', 'TE_bitscore',\n",
    "       'non_meta_top_stitle', 'non_meta_top_pident', 'non_meta_top_bitscore',\n",
    "       'bit_ratio']\n",
    "exclude_TE.to_csv('outputs/TE_bitscore_comparison.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "166886ba-5368-4fcc-a992-b3e2f2cf8bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_TE.to_csv('outputs/TE_bitscore_comparison.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27664357-5147-4521-a105-b6f3ce61a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d789a96a-416f-4cee-b58a-d04ac377ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_TE=exclude_TE[exclude_TE.bit_ratio<1.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d0d78b5-8afe-4d8e-b7fa-75823bd3cae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([\";\".join(x.split(\";\")[0:2]) for x in exclude_TE['query interval']])&set(chimeras_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65ccc9d3-8afa-47c3-b3f6-ca7a99b18e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Non-LTR retrotransposon from Tribolium castaneum.': 2,\n",
       "         'Crypton DNA transposon from the Photinus pyralis genome, consensus.': 7,\n",
       "         'LTR retrotransposon from Bemisia tabaci, internal portion, consensus.': 3,\n",
       "         'L2-type retrotransposon sequence - a consensus.': 1,\n",
       "         'Non-LTR retrotransposon.': 2,\n",
       "         'missing': 8,\n",
       "         'a R1 element from Heliconius melpomene.': 1,\n",
       "         'LTR retrotransposon from the Sitobion miscanthi genome - internal portion consensus.': 1,\n",
       "         'autonomous Polinton DNA transposon - consensus.': 2,\n",
       "         'Non-LTR retrotransposon from the bear giant-skipper genome - consensus.': 6,\n",
       "         'LTR retrotransposon from the Scaptodrosophila lebanonensis genome - internal portion consensus.': 1,\n",
       "         'Non-LTR retrotransposon from the Cydia splendana genome: consensus.': 4,\n",
       "         'LTR retrotransposon from the yellow fever mosquito genome: internal portion.': 8,\n",
       "         'LTR retrotransposon from the boll weevil genome - internal portion consensus.': 1,\n",
       "         'Non-LTR retrotransposon: consensus.': 3,\n",
       "         'LTR retrotransposon from the beet armyworm genome - internal portion consensus.': 1,\n",
       "         'LTR retrotransposon from the Linepithema humile genome: internal portion.': 1,\n",
       "         'LTR retrotransposon from the Drosophila bipectinata genome: internal portion.': 1,\n",
       "         'R1 non-LTR retrotransposon sequence - a consensus.': 2,\n",
       "         'DOC3_DM is a non-LTR retrotransposon.': 1,\n",
       "         'Non-LTR retrotransposon from fruit flies.': 1,\n",
       "         'Non-LTR retrotransposon from Drosophila willistoni.': 1,\n",
       "         'LTR retrotransposon from the Pogonomyrmex barbatus genome: internal portion.': 4,\n",
       "         'Non-LTR retrotransposon from Acyrthosiphon pisum.': 1,\n",
       "         'Complete sequence of retrotransposon SARTTc6.': 1,\n",
       "         'LTR retrotransposon from the migratory locust: internal portion, consensus.': 2,\n",
       "         'Non-LTR retrotransposon from the Dermacentor silvarum genome - consensus.': 3,\n",
       "         'Gypsy LTR-retrotransposon from Nasonia vitripennis, interanl region.': 1,\n",
       "         'DNA transposon from the Copidosoma floridanum genome - consensus.': 1,\n",
       "         'Silkworm Nimb non-LTR retrotransposon - consensus sequence.': 1,\n",
       "         'DNA transposon.': 1,\n",
       "         'Non-LTR retrotransposon from the Drosophila takahashii genome: consensus.': 1,\n",
       "         'Non-LTR retrotransposon family from Heliconius melpomene melpomene.': 1,\n",
       "         'LTR retrotransposon from the Drosophila takahashii genome: internal portion.': 1,\n",
       "         'Non-LTR Retrotransposon, consensus.': 2,\n",
       "         'LTR retrotransposon from the Schizophyllum commune genome: internal portion.': 1,\n",
       "         'Non-LTR retrotransposon, consensus.': 1,\n",
       "         'LTR retrotransposon from the fire ant genome: internal portion.': 1,\n",
       "         'LTR retrotransposon from Nasonia parasitic wasp: internal portion.': 3,\n",
       "         'Bombyx mori TRAS3 gene, non-LTR retrotransposon, complete cds.': 1,\n",
       "         'LTR retrotransposon from the white-legged damselfly genome, internal portion consensus.': 1,\n",
       "         'LTR retrotransposon from the fire ant genome - internal portion consensus.': 1,\n",
       "         'Non-LTR retrotransposon from the coelacanth genome: consensus.': 1,\n",
       "         'LTR retrotransposon from the yellow fever mosquito genome: internal portion, consensus.': 1,\n",
       "         'LTR retrotransposon from the Anopheles funestus genome - internal portion consensus.': 3})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##print out names of TE hits that are filtered out\n",
    "Counter(list(exclude_TE.TE_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd1f8598-2934-45cb-bd07-4d60acef0394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "chimeras_transposon_filtered=defaultdict(dict)\n",
    "for c in chimeras_filtered:\n",
    "    cdict={}\n",
    "    for inter in chimeras[c]:\n",
    "        if c+';'+'HGT_'+str(inter).replace(\" \",'') not in list(exclude_TE['query interval']):\n",
    "            chimeras_transposon_filtered[c][inter]=chimeras_filtered[c][inter]\n",
    "chimeras_transposon_filtered={x:chimeras_transposon_filtered[x] for x in chimeras_transposon_filtered if 'HGT' in chimeras_transposon_filtered[x].values() and 'Meta' in chimeras_transposon_filtered[x].values() }\n",
    "len(chimeras_transposon_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b294811-53fe-46e9-a3a4-45c57c6dc397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store filtered chimeras as a pickle file\n",
    "file_path = 'outputs/transposon_ankyrin_filtered_round2_chimera_intervals.pickle'\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(chimeras_transposon_filtered,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbf4ad74-35dd-49ec-bfb0-1ac3266e405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store filtered chimeras as a pickle file\n",
    "file_path = 'outputs/transposon_ankyrin_filtered_round2_chimera_intervals.pickle'\n",
    "with open(file_path, 'rb') as file:\n",
    "    chimeras_transposon_filtered=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f782cac-8c03-4da6-8abe-2b1e03bcdd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##store filtered chimeras as a list output\n",
    "f=open('outputs/transposon_ankyrin_filtered_round2_chimera_intervals.txt','w')\n",
    "for k,v in chimeras_transposon_filtered.items():\n",
    "    f.write(f\"{k}:{v}\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d79287-1654-4274-ac4b-2596f6c68526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-rishabh]",
   "language": "python",
   "name": "conda-env-.conda-rishabh-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
